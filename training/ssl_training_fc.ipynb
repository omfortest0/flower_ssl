{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import lightly\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "num_workers = 1\n",
    "batch_size = 128\n",
    "seed = 1\n",
    "max_epochs = 20\n",
    "input_size = 128\n",
    "num_ftrs = 32\n",
    "\n",
    "path_to_data = '/content/drive/MyDrive/train_data'\n",
    "\n",
    "collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "    input_size=input_size,\n",
    "    vf_prob=0.5,\n",
    "    rr_prob=0.5\n",
    ")\n",
    "\n",
    "# We create a torchvision transformation for embedding the dataset after\n",
    "# training\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((input_size, input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=lightly.data.collate.imagenet_normalize['mean'],\n",
    "        std=lightly.data.collate.imagenet_normalize['std'],\n",
    "    )\n",
    "])\n",
    "\n",
    "dataset_train_simclr = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_data\n",
    ")\n",
    "\n",
    "dataset_test = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_data,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "dataloader_train_simclr = torch.utils.data.DataLoader(\n",
    "    dataset_train_simclr,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "from lightly.models.modules.heads import SimCLRProjectionHead\n",
    "from lightly.loss import NTXentLoss\n",
    "\n",
    "\n",
    "class SimCLRModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        hidden_dim = resnet.fc.in_features\n",
    "        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, 128)\n",
    "\n",
    "        self.criterion = NTXentLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(h)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optim, max_epochs\n",
    "        )\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "gpus = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "model = SimCLRModel()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs, gpus=gpus, progress_bar_refresh_rate=100\n",
    ")\n",
    "trainer.fit(model, dataloader_train_simclr)\n",
    "\n",
    "\n",
    "def generate_embeddings(model, dataloader):\n",
    "    \"\"\"Generates representations for all images in the dataloader with\n",
    "    the given model\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = []\n",
    "    filenames = []\n",
    "    with torch.no_grad():\n",
    "        for img, label, fnames in dataloader:\n",
    "            img = img.to(model.device)\n",
    "            emb = model.backbone(img).flatten(start_dim=1)\n",
    "            embeddings.append(emb)\n",
    "            filenames.extend(fnames)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, 0)\n",
    "    embeddings = normalize(embeddings)\n",
    "    return embeddings, filenames\n",
    "\n",
    "\n",
    "model.eval()\n",
    "embeddings, filenames = generate_embeddings(model, dataloader_test)\n",
    "\n",
    "def get_image_as_np_array(filename: str):\n",
    "    \"\"\"Returns an image as an numpy array\n",
    "    \"\"\"\n",
    "    img = Image.open(filename)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def plot_knn_examples(embeddings, filenames, n_neighbors=3, num_examples=6):\n",
    "    \"\"\"Plots multiple rows of random images with their nearest neighbors\n",
    "    \"\"\"\n",
    "    # lets look at the nearest neighbors for some samples\n",
    "    # we use the sklearn library\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(embeddings)\n",
    "    distances, indices = nbrs.kneighbors(embeddings)\n",
    "\n",
    "    # get 5 random samples\n",
    "    samples_idx = np.random.choice(len(indices), size=num_examples, replace=False)\n",
    "\n",
    "    # loop through our randomly picked samples\n",
    "    for idx in samples_idx:\n",
    "        fig = plt.figure()\n",
    "        # loop through their nearest neighbors\n",
    "        for plot_x_offset, neighbor_idx in enumerate(indices[idx]):\n",
    "            # add the subplot\n",
    "            ax = fig.add_subplot(1, len(indices[idx]), plot_x_offset + 1)\n",
    "            # get the correponding filename for the current index\n",
    "            fname = os.path.join(path_to_data, filenames[neighbor_idx])\n",
    "            # plot the image\n",
    "            plt.imshow(get_image_as_np_array(fname))\n",
    "            # set the title to the distance of the neighbor\n",
    "            ax.set_title(f'd={distances[idx][plot_x_offset]:.3f}')\n",
    "            # let's disable the axis\n",
    "            plt.axis('off')\n",
    "            \n",
    "# You could use the pre-trained model and train a classifier on top.\n",
    "pretrained_resnet_backbone = model.backbone\n",
    "\n",
    "# you can also store the backbone and use it in another code\n",
    "state_dict = {\n",
    "    'resnet18_parameters': pretrained_resnet_backbone.state_dict()\n",
    "}\n",
    "torch.save(state_dict, '/content/drive/MyDrive/resetnet_train.pth')\n",
    "\n",
    "# load the model in a new file for inference\n",
    "resnet18_new = torchvision.models.resnet18()\n",
    "\n",
    "# note that we need to create exactly the same backbone in order to load the weights\n",
    "backbone_new = nn.Sequential(*list(resnet18_new.children())[:-1])\n",
    "\n",
    "ckpt = torch.load('/content/drive/MyDrive/resnetmodel.pth')\n",
    "backbone_new.load_state_dict(ckpt['resnet18_parameters'])\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class LinearEvaluation(nn.Module):\n",
    "    def __init__(self, model, nu_classes):\n",
    "        super().__init__()\n",
    "        simclr = model\n",
    "        simclr.linear_eval = True\n",
    "        simclr.projection = Identity()\n",
    "        self.simclr = simclr\n",
    "        for param in self.simclr.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.linear = nn.Linear(128, nu_classes)\n",
    "    def forward(self, x):\n",
    "        encoding = self.simclr(x)\n",
    "        pred = self.linear(encoding) \n",
    "        return pred\n",
    "\n",
    "eval_model = LinearEvaluation(model, 102).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(eval_model.parameters())\n",
    "\n",
    "resize = Resize(255)\n",
    "ccrop = CenterCrop(224)\n",
    "ttensor = ToTensor()\n",
    "\n",
    "custom_transform = Compose([\n",
    "    resize,\n",
    "    ccrop,\n",
    "    ttensor,\n",
    "])\n",
    "\n",
    "flowers_ds = ImageFolder(\n",
    "    root=\"/content/drive/MyDrive/train_data_split/\",\n",
    "    transform=custom_transform\n",
    ")\n",
    "\n",
    "nu_classes = len(flowers_ds.classes)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Building the data loader\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    flowers_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=os.cpu_count(),\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "    for i, element in enumerate(train_dl):\n",
    "        image, label = element\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = eval_model(image)\n",
    "        loss = criterion(pred, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print(f'EPOCH: {epoch+1} BATCH: {i+1} LOSS: {(running_loss/100):.4f} ')\n",
    "            running_loss = 0.0\n",
    "    print(f'Time taken: {((time.time()-t0)/60):.3f} mins')\n",
    "    \n",
    "torch.save(eval_model.state_dict(), '/content/drive/MyDrive/eval_model_fc.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
